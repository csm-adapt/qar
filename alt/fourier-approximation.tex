\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=blue,
}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{scalerel,stackengine}

% https://tex.stackexchange.com/a/101136
\stackMath
\newcommand\reallywidehat[1]{%
\savestack{\tmpbox}{\stretchto{%
  \scaleto{%
    \scalerel*[\widthof{\ensuremath{#1}}]{\kern-.6pt\bigwedge\kern-.6pt}%
    {\rule[-\textheight/2]{1ex}{\textheight}}%WIDTH-LIMITED BIG WEDGE
  }{\textheight}% 
}{0.5ex}}%
\stackon[1pt]{#1}{\tmpbox}%
}

\title{Fourier Series Iteration of a Neural Network}
\date{\today}

\setlength{\parindent}{0pt}

\begin{document}

\maketitle

\section{Notation}
\subsection{Fourier Series}
We write the Fourier series expansion $\hat{f}: \mathbb{R} \to \mathbb{R}$ of a function $f: \mathbb{R} \to \mathbb{R}$ as
\begin{equation}
    \hat{f}(x) = \frac{1}{\sqrt{2\pi}} \sum_{n=-\infty}^{\infty} c_n e^{inx},
\end{equation}
where
\begin{equation}
    c_n = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} f(x) e^{-inx} dx.
\end{equation}
When expanding an $m$-dimensional function, we use the following generalization.
\begin{equation}
    \hat{f}(x_1, \ldots, x_m) = \frac{1}{(2\pi)^{m/2}}\sum_{n_1=-\infty}^{\infty} \cdots \sum_{n_m=-\infty}^{\infty} c_{n_1, \ldots, n_m} e^{i(n_1x_1 + \cdots + n_mx_m)}
\end{equation}
where
\begin{equation}
    c_{n_1, \ldots, n_m} = \frac{1}{(2\pi)^{m/2}}\int_{\mathbb{R}^m} f(x_1, \ldots, x_m) e^{-i(n_1x_1 + \cdots + n_mx_m)} dx.
\end{equation}

If we wish to truncate a Fourier series to $N_1, \ldots, N_m$ terms, we use the truncated Fourier series denoted by $\hat{f}_{N_1, \ldots, N_M}$ which is defined by
\begin{equation}
    \hat{f}_{N_1, \ldots, N_m}(x_1, \ldots, x_m) = \frac{1}{(2\pi)^{m/2}}\sum_{n_1=-N_1}^{N_1} \cdots \sum_{n_m=-N_M}^{N_M} c_{n_1, \ldots, n_m} e^{i(n_1x_1 + \cdots + n_mx_m)}.
\end{equation}

\subsection{Neural Network}
We represent an arbitrary $L$-layer neural network by the function
\begin{equation}
    y(x) = \sigma_L(W_L \cdots \sigma_1(W_1 x) \cdots).
\end{equation}
where $W_i$ is the weight matrix for the $i$-th layer and $\sigma_i$ is the activation function for the $i$-th layer. We can rewrite this iteratively.
\begin{align}
    x_1(x) &= x \\
    x_{i+1}(x) &= \sigma_i(W_i x_i(x))
\end{align}
so that $y = x_{L+1}$.

\section{Approximation}
We wish to construct a Fourier approximation to a neural network layer by layer. For computational feasibility, we will assume that our Fourier series approximation is truncated to $N$ terms. That is, the $i$-th layer of a neural network is a function of the input $x$ defined by
\begin{align}
    \hat{f}_1(x) = \hat{x}_1(x) &= \sum_{n=-N}^{-1} i\frac{(-1)^n}{n} +  \sum_{n=1}^{N} i\frac{(-1)^n}{n}, \\
    \hat{f}_i(x) = \hat{x}_i(x) &= \reallywidehat{(\sigma_{i-1} \circ w_{i-1} \circ \hat{f}_{i-1})}(x).
\end{align}
We can compute $\hat{f}_i(x)$ using quadrature or a discrete Fourier transform over many gridpoints of its definition. The algorithm to perform the approximation iteratively is as follows:

{\centering
\begin{minipage}{0.8\linewidth}
\begin{algorithm}[H]
\caption{Iterative Approximation Algorithm}
\begin{algorithmic}[1]
    \Procedure{Fourier Approximation}{$(\sigma_1, W_1), \ldots, (\sigma_L, W_L)$}
        \State $\hat{f}_1 \gets \hat{x}_1 = \sum_{n=-N}^{-1} i\frac{(-1)^n}{n} +  \sum_{n=1}^{N} i\frac{(-1)^n}{n}$
        \For{$i = 2, \ldots, L+1$}
            \For{$n = -N, \ldots, N$}
                \State $c_{i,n} \gets \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} \sigma_{i-1}(W_{i-1}f_{i-1}(x)) e^{-inx} dx$ \Comment{Use Quadrature or DFT}
            \EndFor
            \State $\hat{f}_i(x) \gets \frac{1}{\sqrt{2\pi}} \sum_{n=-\infty}^{\infty} c_{i,n} e^{inx}$
        \EndFor
        \State $y \gets f_{L+1}(x)$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
\end{minipage}
\par
\vspace{12pt}
}

This algorithm operates on a single input dimension but can easily be extend to multidimensional approximations.

\end{document}